{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face Hub as a vector search backend\n",
    "\n",
    "We will be using the [smol-blueprint/hf-blogs](https://huggingface.co/datasets/smol-blueprint/hf-blogs) dataset, which is a dataset that contains the blogs from the Hugging Face website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'author', 'date', 'local', 'tags', 'URL', 'content'],\n",
       "    num_rows: 312\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"smol-blueprint/hf-blogs\")\n",
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking the documents\n",
    "\n",
    "To understand how to chunk the documents, we will first need to understand what our `content` column looks like. As we can see above, the content is formatted as a markdown file. Therefore, we know that our text is structured in paragraphs using header indicators like `#` or `##`, and that we can use these to split the text into chunks that are semantically meaningful. Let's write a function that does this. Similarly, we can extract things like images by using something like `BeautifulSoup.find_all(name=\"img\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'author', 'date', 'local', 'tags', 'URL', 'content', 'chunked_content'],\n",
       "    num_rows: 312\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "counter = 0\n",
    "def structure_content(row):\n",
    "    soup = BeautifulSoup(markdown.markdown(row[\"content\"]))\n",
    "    # Split on 2 or more # followed by space\n",
    "    chunks = re.split(r'#{2,}\\s', string=soup.text)\n",
    "    # Filter empty chunks and add back the # prefix except for first chunk\n",
    "    row[\"chunked_content\"] = list(set([chunk for chunk in chunks if chunk.strip()]))\n",
    "    return row\n",
    "\n",
    "chunked_dataset = dataset.map(structure_content)\n",
    "chunked_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunked content seems reasonable, so we can now continue to the next step, which is creating embeddings for each of our content items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating embeddings\n",
    "\n",
    "In order to create a vector search index, we will need to create embeddings for each of our chunks. We will use the [Hugging Face `sentence-transformers` library](https://huggingface.co/sentence-transformers) to create these embeddings. \n",
    "\n",
    "### Creating text embeddings\n",
    "\n",
    "You can find the best models using the [MTEB leaderboard](https://huggingface.co/spaces/mteb/leaderboard) but don't forget to always check the performance of the model on your specific task. We will use the [Snowflake/snowflake-arctic-embed-m-v1.5](https://huggingface.co/Snowflake/snowflake-arctic-embed-m-v1.5) model to create the embeddings for our text, which we chose because it performs well on assymetric search on benchmarks, i.e., query-answer pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2928/2928 [00:37<00:00, 77.47 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 220.37ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/smol-blueprint/hf-blogs-text-embeddings/commit/2d591a05d27787543db5b29d0b7596bd4b2e157d', commit_message='Upload dataset', commit_description='', oid='2d591a05d27787543db5b29d0b7596bd4b2e157d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/smol-blueprint/hf-blogs-text-embeddings', endpoint='https://huggingface.co', repo_type='dataset', repo_id='smol-blueprint/hf-blogs-text-embeddings'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import Dataset\n",
    "\n",
    "model = SentenceTransformer(\"Snowflake/snowflake-arctic-embed-m-v1.5\")\n",
    "\n",
    "def extract_chunks(dataset):\n",
    "    \"\"\"Extract chunks from dataset while removing unnecessary fields.\"\"\"\n",
    "    data = []\n",
    "    excluded_fields = {\"chunked_content\", \"images\", \"content\", \"code\", \"image\"}\n",
    "    \n",
    "    for row in dataset[\"train\"]:\n",
    "        for chunk in row[\"chunked_content\"]:\n",
    "            # Create new dict with only desired fields rather than copying\n",
    "            item = {}\n",
    "            for k,v in row.items():\n",
    "                if k not in excluded_fields:\n",
    "                    item[k] = v\n",
    "            item[\"chunk\"] = chunk\n",
    "            data.append(item)\n",
    "    return data\n",
    "\n",
    "def create_text_embeddings(batch):\n",
    "    \"\"\"Create embeddings for a batch of text chunks.\"\"\"\n",
    "    batch[\"embedding\"] = model.encode(batch[\"chunk\"])\n",
    "    return batch\n",
    "\n",
    "# Create dataset with chunks and generate embeddings\n",
    "chunks = extract_chunks(chunked_dataset)\n",
    "embeddings_dataset = Dataset.from_list(chunks)\n",
    "embeddings_dataset.map(create_text_embeddings, batched=True)\n",
    "embeddings_dataset.push_to_hub(\"smol-blueprint/hf-blogs-text-embeddings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating multi-modal embeddings\n",
    "\n",
    "We can use use a similar approach to create embeddings for our images and texts. We will use the [sentence-transformers/clip-ViT-B-32](https://huggingface.co/sentence-transformers/clip-ViT-B-32) model to create the embeddings for our images and texts which will then be embedded into a single vector space. This is a larger model which means it will take longer to embed the content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector search Hub datasets\n",
    "\n",
    "For the similarity search, we will can simply execute queries on top of the Hugging Face Hub using the [DuckDB integration for vector search](https://huggingface.co/docs/hub/en/datasets-duckdb). This also works with [private datasets](https://huggingface.co/docs/hub/en/datasets-duckdb-auth). Note that we need to use the same model for embedding the query as we used for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidberenstein/Documents/programming/smol-project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>local</th>\n",
       "      <th>tags</th>\n",
       "      <th>URL</th>\n",
       "      <th>chunk</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Federated Learning using Hugging Face and Flower</td>\n",
       "      <td>charlesbvll</td>\n",
       "      <td>March 27, 2023</td>\n",
       "      <td>fl-with-flower</td>\n",
       "      <td>nlp, transformers, guide, flower, federated-le...</td>\n",
       "      <td>https://huggingface.co/blog/fl-with-flower</td>\n",
       "      <td>Standard Hugging Face workflow</td>\n",
       "      <td>0.109720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Hugging Face Hub for Galleries, Libraries,...</td>\n",
       "      <td>davanstrien</td>\n",
       "      <td>June 12, 2023</td>\n",
       "      <td>hf-hub-glam-guide</td>\n",
       "      <td>community, guide</td>\n",
       "      <td>https://huggingface.co/blog/hf-hub-glam-guide</td>\n",
       "      <td>What can you find on the Hugging Face Hub?</td>\n",
       "      <td>0.122290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How Hugging Face Accelerated Development of Wi...</td>\n",
       "      <td>Violette</td>\n",
       "      <td>March 1, 2023</td>\n",
       "      <td>classification-use-cases</td>\n",
       "      <td>nlp, case-studies</td>\n",
       "      <td>https://huggingface.co/blog/classification-use...</td>\n",
       "      <td>Solutions provided by the Hugging Face Experts...</td>\n",
       "      <td>0.132556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hugging Face's TensorFlow Philosophy</td>\n",
       "      <td>rocketknight1</td>\n",
       "      <td>August 12, 2022</td>\n",
       "      <td>tensorflow-philosophy</td>\n",
       "      <td>nlp, cv, guide</td>\n",
       "      <td>https://huggingface.co/blog/tensorflow-philosophy</td>\n",
       "      <td># Hugging Face's TensorFlow Philosophy</td>\n",
       "      <td>0.141068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creating open machine learning datasets? Share...</td>\n",
       "      <td>davanstrien</td>\n",
       "      <td>October 30, 2023</td>\n",
       "      <td>researcher-dataset-sharing</td>\n",
       "      <td>community, research, datasets, guide</td>\n",
       "      <td>https://huggingface.co/blog/researcher-dataset...</td>\n",
       "      <td># Creating open machine learning datasets? Sha...</td>\n",
       "      <td>0.155733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title         author  \\\n",
       "0   Federated Learning using Hugging Face and Flower    charlesbvll   \n",
       "1  The Hugging Face Hub for Galleries, Libraries,...    davanstrien   \n",
       "2  How Hugging Face Accelerated Development of Wi...       Violette   \n",
       "3               Hugging Face's TensorFlow Philosophy  rocketknight1   \n",
       "4  Creating open machine learning datasets? Share...    davanstrien   \n",
       "\n",
       "               date                       local  \\\n",
       "0    March 27, 2023              fl-with-flower   \n",
       "1     June 12, 2023           hf-hub-glam-guide   \n",
       "2     March 1, 2023    classification-use-cases   \n",
       "3   August 12, 2022       tensorflow-philosophy   \n",
       "4  October 30, 2023  researcher-dataset-sharing   \n",
       "\n",
       "                                                tags  \\\n",
       "0  nlp, transformers, guide, flower, federated-le...   \n",
       "1                                   community, guide   \n",
       "2                                  nlp, case-studies   \n",
       "3                                     nlp, cv, guide   \n",
       "4               community, research, datasets, guide   \n",
       "\n",
       "                                                 URL  \\\n",
       "0         https://huggingface.co/blog/fl-with-flower   \n",
       "1      https://huggingface.co/blog/hf-hub-glam-guide   \n",
       "2  https://huggingface.co/blog/classification-use...   \n",
       "3  https://huggingface.co/blog/tensorflow-philosophy   \n",
       "4  https://huggingface.co/blog/researcher-dataset...   \n",
       "\n",
       "                                               chunk  distance  \n",
       "0                   Standard Hugging Face workflow    0.109720  \n",
       "1       What can you find on the Hugging Face Hub?    0.122290  \n",
       "2  Solutions provided by the Hugging Face Experts...  0.132556  \n",
       "3         # Hugging Face's TensorFlow Philosophy      0.141068  \n",
       "4  # Creating open machine learning datasets? Sha...  0.155733  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import duckdb\n",
    "\n",
    "model = SentenceTransformer(\"Snowflake/snowflake-arctic-embed-m-v1.5\")\n",
    "\n",
    "def similarity_search(\n",
    "    query: str, \n",
    "    k: int = 5, \n",
    "    dataset_name: str = \"smol-blueprint/hf-blogs-text-embeddings\", \n",
    "    embedding_column: str = \"embedding\",\n",
    "):\n",
    "    # Use same model as used for indexing\n",
    "    query_vector = model.encode(query)\n",
    "    embedding_dim = model.get_sentence_embedding_dimension()\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "        SELECT \n",
    "            title,\n",
    "            author,\n",
    "            date,\n",
    "            local,\n",
    "            tags,\n",
    "            URL,\n",
    "            chunk,\n",
    "            array_cosine_distance(\n",
    "                {embedding_column}::float[{embedding_dim}], \n",
    "                {query_vector.tolist()}::float[{embedding_dim}]\n",
    "            ) as distance\n",
    "        FROM 'hf://datasets/{dataset_name}/**/*.parquet'\n",
    "        ORDER BY distance\n",
    "        LIMIT {k}\n",
    "    \"\"\"\n",
    "    \n",
    "    return duckdb.sql(sql).to_df()\n",
    "\n",
    "similarity_search(\"What is the best way to learn Hugging Face?\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio as vector search interface\n",
    "\n",
    "We will be using Gradio as web application tool to create a demo interface for our vector search index. We can develop this locally and then easily deploy it to Hugging Face Spaces. Lastly, we can use the Gradio client as SDK to directly interact with our vector search index.\n",
    "\n",
    "### Gradio as sharable app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def search(query, k):\n",
    "    return similarity_search(query, k)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"\"\"# Vector Search Hub Datasets\n",
    "                \n",
    "                Part of [smol blueprint](https://github.com/davidberenstein1957/smol-blueprint) - a smol blueprint for AI development, focusing on practical examples of RAG, information extraction, analysis and fine-tuning in the age of LLMs. \"\"\")\n",
    "    query = gr.Textbox(label=\"Query\")\n",
    "    k = gr.Slider(1, 10, value=5, label=\"Number of results\")\n",
    "    btn = gr.Button(\"Search\")\n",
    "    results = gr.Dataframe(headers=[\"title\", \"url\", \"content\", \"distance\"])\n",
    "    btn.click(fn=search, inputs=[query, k], outputs=[results])\n",
    "    \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Gradio to Hugging Face Spaces\n",
    "\n",
    "We can now [deploy our Gradio application to Hugging Face Spaces](https://huggingface.co/new-space?sdk=gradio&name=vector-search-hub). Follow the redirect and then click on the \"Create Space\" button. After that, you can copy the code from the Gradio interface and paste it into an `app.py` file. Don't forget to copy the `similarity_search` function from the notebook and paste it into the `app.py` file. Lastly, you need to create an `requirements.txt` file with and with the following content:\n",
    "\n",
    "```bash\n",
    "duckdb\n",
    "sentence-transformers\n",
    "```\n",
    "\n",
    "We wait a couple of minutes for the application to deploy et voila, we have [a public vector search interface](https://huggingface.co/spaces/smol-blueprint/vector-search-hub)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio as Rest API\n",
    "\n",
    "We can now use the [Gradio client as SDK](https://www.gradio.app/guides/getting-started-with-the-python-client) to directly interact with our vector search index. Each Gradio app has a API documentation that describes the available endpoints and their parameters, which you can access from the button at the bottom of the Gradio app's space page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidberenstein/Documents/programming/smol-project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://smol-blueprint-vector-search-hub.hf.space/ ✔\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>local</th>\n",
       "      <th>tags</th>\n",
       "      <th>URL</th>\n",
       "      <th>chunk</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Introducing the Private Hub: A New Way to Buil...</td>\n",
       "      <td>FedericoPascual</td>\n",
       "      <td>August 3, 2022</td>\n",
       "      <td>introducing-private-hub</td>\n",
       "      <td>announcement, enterprise, hub</td>\n",
       "      <td>https://huggingface.co/blog/introducing-privat...</td>\n",
       "      <td>Training accurate models faster</td>\n",
       "      <td>0.192108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fine-tuning Llama 2 70B using PyTorch FSDP</td>\n",
       "      <td>smangrul</td>\n",
       "      <td>September 13, 2023</td>\n",
       "      <td>ram-efficient-pytorch-fsdp</td>\n",
       "      <td>llm, guide, nlp</td>\n",
       "      <td>https://huggingface.co/blog/ram-efficient-pyto...</td>\n",
       "      <td>Fine-Tuning</td>\n",
       "      <td>0.193254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Making ML-powered web games with Transformers.js</td>\n",
       "      <td>Xenova</td>\n",
       "      <td>July 5, 2023</td>\n",
       "      <td>ml-web-games</td>\n",
       "      <td>game-dev, guide, web, javascript, transformers.js</td>\n",
       "      <td>https://huggingface.co/blog/ml-web-games</td>\n",
       "      <td>1. Training the neural network</td>\n",
       "      <td>0.196486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Open-Source Text Generation &amp; LLM Ecosystem at...</td>\n",
       "      <td>merve</td>\n",
       "      <td>July 17, 2023</td>\n",
       "      <td>os-llms</td>\n",
       "      <td>LLM, inference, nlp</td>\n",
       "      <td>https://huggingface.co/blog/os-llms</td>\n",
       "      <td>Tools in the Hugging Face Ecosystem for LLM Se...</td>\n",
       "      <td>0.197265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comparing the Performance of LLMs: A Deep Dive...</td>\n",
       "      <td>mehdiiraqui</td>\n",
       "      <td>November 7, 2023</td>\n",
       "      <td>Lora-for-sequence-classification-with-Roberta-...</td>\n",
       "      <td>nlp, guide, llm, peft</td>\n",
       "      <td>https://huggingface.co/blog/Lora-for-sequence-...</td>\n",
       "      <td>Pre-trained Models</td>\n",
       "      <td>0.198704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title           author  \\\n",
       "0  Introducing the Private Hub: A New Way to Buil...  FedericoPascual   \n",
       "1         Fine-tuning Llama 2 70B using PyTorch FSDP         smangrul   \n",
       "2   Making ML-powered web games with Transformers.js           Xenova   \n",
       "3  Open-Source Text Generation & LLM Ecosystem at...            merve   \n",
       "4  Comparing the Performance of LLMs: A Deep Dive...      mehdiiraqui   \n",
       "\n",
       "                 date                                              local  \\\n",
       "0      August 3, 2022                            introducing-private-hub   \n",
       "1  September 13, 2023                         ram-efficient-pytorch-fsdp   \n",
       "2        July 5, 2023                                       ml-web-games   \n",
       "3       July 17, 2023                                            os-llms   \n",
       "4    November 7, 2023  Lora-for-sequence-classification-with-Roberta-...   \n",
       "\n",
       "                                                tags  \\\n",
       "0                      announcement, enterprise, hub   \n",
       "1                                    llm, guide, nlp   \n",
       "2  game-dev, guide, web, javascript, transformers.js   \n",
       "3                                LLM, inference, nlp   \n",
       "4                              nlp, guide, llm, peft   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://huggingface.co/blog/introducing-privat...   \n",
       "1  https://huggingface.co/blog/ram-efficient-pyto...   \n",
       "2           https://huggingface.co/blog/ml-web-games   \n",
       "3                https://huggingface.co/blog/os-llms   \n",
       "4  https://huggingface.co/blog/Lora-for-sequence-...   \n",
       "\n",
       "                                               chunk  distance  \n",
       "0                  Training accurate models faster    0.192108  \n",
       "1                                      Fine-Tuning    0.193254  \n",
       "2                   1. Training the neural network    0.196486  \n",
       "3  Tools in the Hugging Face Ecosystem for LLM Se...  0.197265  \n",
       "4                               Pre-trained Models    0.198704  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gradio_client import Client\n",
    "import pandas as pd\n",
    "\n",
    "client = Client(\"https://smol-blueprint-vector-search-hub.hf.space/\")\n",
    "results = client.predict(\n",
    "    api_name=\"/similarity_search\",\n",
    "    query=\"Optimizing LLM inference\", \n",
    "    k=5\n",
    ")\n",
    "pd.DataFrame(data=results[\"data\"], columns=results[\"headers\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
